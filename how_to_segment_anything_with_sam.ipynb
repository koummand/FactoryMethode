{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPFLECoCL5KkEX5vjEiOZ4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koummand/FactoryMethode/blob/master/how_to_segment_anything_with_sam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WDSnf016-m6",
        "outputId": "588ef912-db45-4149-a803-8ec5327ffa84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 15 20:05:51 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you start"
      ],
      "metadata": {
        "id": "DQUlieniYaJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before you start\n",
        "import os\n",
        "HOME=os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4zZYj2w7b5Z",
        "outputId": "76eaa356-ee7f-4ec7-c55e-39d05b4b4b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOME: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install segment anything model(SAM) and other dependenciess\n",
        "%cd {HOME}\n",
        "import sys\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkTsgW9L8FGo",
        "outputId": "714e77b8-99ba-4d9f-e449-db3f621ec0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-mg5z0dnk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-mg5z0dnk\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment-anything\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36588 sha256=cdecf523551efa0c6cb1f859ea6d4e3147ae273be6158fb308c7d05bc0254f44\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eb4ugp48/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment-anything\n",
            "Installing collected packages: segment-anything\n",
            "Successfully installed segment-anything-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3Vistkc8-Cm",
        "outputId": "7be6e06d-7e80-40f9-f446-8a6a3596daff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/367.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/367.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download sam\n",
        "%cd {HOME}\n",
        "!mkdir {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de02B-xVAf15",
        "outputId": "cab37ebd-f380-471c-8032-11214f681f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH= os.path.join(HOME, 'weights', 'sam_vit_h_4b8939.pth')\n",
        "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_4Ys1BlCkK1",
        "outputId": "45316fe9-02f6-47b4-f500-0d8bcc0202c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weights/sam_vit_h_4b8939.pth ; exist: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download example data\n",
        "%cd {HOME}\n",
        "!mkdir {HOME}/data\n",
        "%cd {HOME}/data\n",
        "\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-2.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-3.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-4.jpeg"
      ],
      "metadata": {
        "id": "8C2zYpkRv6da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f5a901-a6cc-481f-bef8-2d6c2449b9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download example data\n",
        "import torch\n",
        "\n",
        "DEVICE=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE= \"vit_h\""
      ],
      "metadata": {
        "id": "Q6O1xY1kGGMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "sam=sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)"
      ],
      "metadata": {
        "id": "X10YEM6dHWls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download example data\n",
        "mask_generator=SamAutomaticMaskGenerator(sam)"
      ],
      "metadata": {
        "id": "tM-Yvo0hKB-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "IMAGE_NAME= \"dog.jpeg\"\n",
        "IMAGE_PATH=os.path.join(HOME, \"data\", IMAGE_NAME)"
      ],
      "metadata": {
        "id": "TXeWW8hBJanP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate mask with sam\n",
        "import cv2\n",
        "import supervision as sv\n",
        "\n",
        "image_bgr=cv2.imread(IMAGE_PATH)\n",
        "image_rgb=cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "sam_result= mask_generator.generate(image_rgb)"
      ],
      "metadata": {
        "id": "Tphs3rEjwfCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sam_result[0].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfLwEnF_05fo",
        "outputId": "ce88ffbe-2f42-452c-9886-25af4c5ee3df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['segmentation', 'area', 'bbox', 'predicted_iou', 'point_coords', 'stability_score', 'crop_box'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results visualisation with supervision\n",
        "mask_annotator= sv.MaskAnnotator()\n",
        "\n",
        "detections = sv.Detections.from_sam(sam_result=sam_result)\n",
        "\n",
        "annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=[image_bgr, annotated_image],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['source image', 'segmented image']\n",
        ")"
      ],
      "metadata": {
        "id": "d3bq9z1j132P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "3819fc68-e0f7-4b90-9a9b-33bacd83747a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-676c4eb8c183>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_sam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msam_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msam_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mannotated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_annotator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_bgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m sv.plot_images_grid(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/supervision/annotators/core.py\u001b[0m in \u001b[0;36mannotate\u001b[0;34m(self, scene, detections, custom_color_lookup)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdetection_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             color = resolve_color(\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mdetections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/supervision/annotators/utils.py\u001b[0m in \u001b[0;36mresolve_color\u001b[0;34m(color, detections, detection_idx, color_lookup)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mcolor_lookup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mColorLookup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColorLookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m ) -> Color:\n\u001b[0;32m---> 78\u001b[0;31m     idx = resolve_color_idx(\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mdetection_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/supervision/annotators/utils.py\u001b[0m in \u001b[0;36mresolve_color_idx\u001b[0;34m(detections, detection_idx, color_lookup)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcolor_lookup\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mColorLookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0;34m\"Could not resolve color by class because\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;34m\"Detections do not have class_id\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Could not resolve color by class becauseDetections do not have class_id"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "how many mask we have"
      ],
      "metadata": {
        "id": "WI6v-oypKVRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# results visualisation with supervision\n",
        "masks = [\n",
        "    mask['segmentation']\n",
        "    for mask\n",
        "    in sorted(sam_result, key=lambda x: x['area'], reverse=True)\n",
        "]\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=masks,\n",
        "    grid_size=(8, int(len(masks) / 8)),\n",
        "    size=(16, 16)\n",
        ")"
      ],
      "metadata": {
        "id": "nvEr4Ir6JzJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate segmentation with bounding Box"
      ],
      "metadata": {
        "id": "ACdqL733MIfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# results visualisation with supervision\n",
        "mask_predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "b741R4ClL6JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "IMAGE_NAME= \"dog.jpeg\"\n",
        "IMAGE_PATH= os.path.join(HOME,\"data\", IMAGE_NAME)"
      ],
      "metadata": {
        "id": "PJAnj_9gMhC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw Box\n",
        "\n",
        "import base64\n",
        "\n",
        "def encode_image(filepath):\n",
        "  with open(filepath, 'rb') as f:\n",
        "    image_bytes = f.read()\n",
        "  encoded = str(base64.64encode(image_bytes), 'utf-8')\n",
        "  return \"data:image/jpg;base64,\"+encoded"
      ],
      "metadata": {
        "id": "ky7hcGZC-Gh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_COLAB =True\n",
        "\n",
        "if IS_COLAB:\n",
        "  from google.colab import output\n",
        "    output.enable_custom_widget_manger()\n",
        "\n",
        "#333\n",
        "from jupyter_bbox_widget import BBoxWidget\n",
        "\n",
        "widget = BBoxWidget()\n",
        "widget.image = encode_image(IMAGE_PATH)\n",
        "widget\n"
      ],
      "metadata": {
        "id": "gwTxBop6O3oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#333"
      ],
      "metadata": {
        "id": "0zGUyfghnrh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "widget.bboxes"
      ],
      "metadata": {
        "id": "kq4dnkOuQXfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# default_box is going to be used if you will not draw any box on image above\n",
        "default_box={'x': 68, 'y': 247, 'width': 555, 'height': 678, 'label': ''}\n",
        "\n",
        "box = widget.bboxes[0] if widget.bboxes else default_box\n",
        "box = np.array([\n",
        "    box['x'],\n",
        "    box['y'],\n",
        "    box['x'] + box['width'],\n",
        "    box['y'] + box['height']\n",
        "])"
      ],
      "metadata": {
        "id": "WjXP6e4lR6l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate masks with SAM"
      ],
      "metadata": {
        "id": "rToSYRvmQr-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "image_bgr= cv2.imread(IMAGE_PATH)\n",
        "image_rgb= cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mask_predictor.set_image(image_rgb)\n",
        "\n",
        "masks, scores, logits = mask_predictor.predict(\n",
        "    box=box,\n",
        "    multimask_output=True\n",
        ")"
      ],
      "metadata": {
        "id": "N-GUa95-Qq6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results Visualisation With Supervision"
      ],
      "metadata": {
        "id": "ZlY2xNbGWFZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_annotator = sv.MaskAnnotator()\n",
        "\n",
        "detections = sv.Detections(\n",
        "    xyxy=sv.mask_to_xyxy(masks=masks),\n",
        "    mask=masks\n",
        ")\n",
        "\n",
        "annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections= dectections)\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=[image_bgr, annotated_image],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['source image', 'segmented image']\n",
        ")"
      ],
      "metadata": {
        "id": "GJA2_WpJWEt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "interaction with segmentation results"
      ],
      "metadata": {
        "id": "yWUVOCo2Z4y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as v\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=masks,\n",
        "    grid_size(1, 4),\n",
        "    size(16, 4)\n",
        ")"
      ],
      "metadata": {
        "id": "BwTNG28lZ4Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "download dataset from roboflow"
      ],
      "metadata": {
        "id": "M5WNnabGtcDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "import roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "roboflow.login()\n",
        "\n",
        "rf= Roboflow()\n",
        "\n",
        "project = rf.workspace(\"hashira-fhxp\").project(\"mri-brain-tumor\")\n",
        "dataset = project.version(1).download(\"coco\")\n",
        "\n",
        "#insert token after load this block"
      ],
      "metadata": {
        "id": "-hbiGUPFtB59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATA_SET_SUBDIRECTORY = \"test\"\n",
        "ANNOTATIONS_FILE_NAME = \"annotations.coco.json\"\n",
        "IMAGES_DIRECTORY_PATH = os.path.join(dataset.location, DATA_SET_SUBDIRECTORY)\n",
        "ANNOTATIONS_FILE_PATH = os.path.join(dataset.location, DATA_SET_SUBDIRECTORY, ANNOTATIONS_FILE_NAME)"
      ],
      "metadata": {
        "id": "syEcNFOuu27w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coco_data = load_coco_json(json_file=ANNOTATIONS_FILE_PATH)\n",
        "\n",
        "CLASSES = [\n",
        "    category.name\n",
        "    for category\n",
        "    in coco_data.categories\n",
        "    if category.supercategory != 'none'\n",
        "]\n",
        "\n",
        "IMAGES = [\n",
        "    image.file_name\n",
        "    for image\n",
        "    in coco_data.images\n",
        "]"
      ],
      "metadata": {
        "id": "bDPfQ3CXwLEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES"
      ],
      "metadata": {
        "id": "ZFeMF4Ujx8h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single image Bounding Box to Mask"
      ],
      "metadata": {
        "id": "wtoODIB6yKJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set random seed to allow easy reproduction of the experiment\n",
        "\n",
        "import random\n",
        "random.seed(10)"
      ],
      "metadata": {
        "id": "EIr6da8MyH4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EXAMPLE_IMAGE_NAME = random.choice(IMAGES)\n",
        "EXAMPLE_IMAGE_PATH = os.path.join(dataset.location, DATA_SETSUBDIRECTORY, EXAMPLE_IMAGE_NAME)\n",
        "\n",
        "#load dataset annotations\n",
        "annotations= COCOJsonUtility.get_annotations_by_image_path(coco_data, image_path= EXAMPLE_IMAGE_NAME)\n",
        "ground_truth = COCOJsonUtility.annotations2detections(annotations=annotations)\n",
        "\n",
        "#small hack - coco numerate classes from 1, model from 0 + we drop first redundant class from coco json\n",
        "ground_truth.class_id = ground_truth.class_id - 1\n",
        "\n",
        "#load image\n",
        "image_bgr = cv2.imread(EXAMPLE_IMAGE_PATH)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#initiate annatator\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "mask_annotator = sv.MaskAnnotator()\n",
        "\n",
        "# annotate ground truth\n",
        "labels = [\n",
        "    f\"{CLASSES[class_id]}\"\n",
        "    for _, _, _, class_id, _\n",
        "    in ground_truth\n",
        "]\n",
        "\n",
        "annotated_frame_ground_truth = box_annotator.annotate(scene=image_bgr.copy(), detections=ground_truth, labels=labels)\n",
        "\n",
        "#run SAM inference\n",
        "mask_predictor.set_image(image_rgb)\n",
        "\n",
        "masks, scores, logits = mask_predictor.predict(\n",
        "    box=ground_truth.xyxy=[0],\n",
        "    multimask_output= True\n",
        ")\n",
        "\n",
        "detections = sv.Detections(\n",
        "    xyxy=sv.mask_to_xyxy(masks=masks),\n",
        "    mask=masks\n",
        ")\n",
        "\n",
        "annotated_image = mask_annotator.annotate(scene= image_bgr.copy(), detections=detections)\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=[annotated_frame_ground_truth, annotated_image],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['source image', 'segmented image']\n",
        ")"
      ],
      "metadata": {
        "id": "FDx5RSLEysW6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}